{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "\n",
    "def dcg_score(y_true, y_score, k=5):\n",
    "   \"\"\"Discounted cumulative gain (DCG) at rank K.\n",
    "\n",
    "   Parameters\n",
    "   ----------\n",
    "   y_true : array, shape = [n_samples]\n",
    "       Ground truth (true relevance labels).\n",
    "   y_score : array, shape = [n_samples, n_classes]\n",
    "       Predicted scores.\n",
    "   k : int\n",
    "       Rank.\n",
    "\n",
    "   Returns\n",
    "   -------\n",
    "   score : float\n",
    "   \"\"\"\n",
    "   order = np.argsort(y_score)[::-1]\n",
    "   y_true = np.take(y_true, order[:k])\n",
    "\n",
    "   gain = 2 ** y_true - 1\n",
    "\n",
    "   discounts = np.log2(np.arange(len(y_true)) + 2)\n",
    "   return np.sum(gain / discounts)\n",
    "\n",
    "\n",
    "def ndcg_score(ground_truth, predictions, k=5):\n",
    "   \"\"\"Normalized discounted cumulative gain (NDCG) at rank K.\n",
    "\n",
    "   Normalized Discounted Cumulative Gain (NDCG) measures the performance of a\n",
    "   recommendation system based on the graded relevance of the recommended\n",
    "   entities. It varies from 0.0 to 1.0, with 1.0 representing the ideal\n",
    "   ranking of the entities.\n",
    "\n",
    "   Parameters\n",
    "   ----------\n",
    "   ground_truth : array, shape = [n_samples]\n",
    "       Ground truth (true labels represended as integers).\n",
    "   predictions : array, shape = [n_samples, n_classes]\n",
    "       Predicted probabilities.\n",
    "   k : int\n",
    "       Rank.\n",
    "\n",
    "   Returns\n",
    "   -------\n",
    "   score : float\n",
    "\n",
    "   Example\n",
    "   -------\n",
    "   >>> ground_truth = [1, 0, 2]\n",
    "   >>> predictions = [[0.15, 0.55, 0.2], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "   >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "   1.0\n",
    "   >>> predictions = [[0.9, 0.5, 0.8], [0.7, 0.2, 0.1], [0.06, 0.04, 0.9]]\n",
    "   >>> score = ndcg_score(ground_truth, predictions, k=2)\n",
    "   0.6666666666\n",
    "   \"\"\"\n",
    "   lb = LabelBinarizer()\n",
    "   lb.fit(range(len(predictions) + 1))\n",
    "   T = lb.transform(ground_truth)\n",
    "\n",
    "   scores = []\n",
    "\n",
    "   # Iterate over each y_true and compute the DCG score\n",
    "   for y_true, y_score in zip(T, predictions):\n",
    "       actual = dcg_score(y_true, y_score, k)\n",
    "       best = dcg_score(y_true, y_true, k)\n",
    "       score = float(actual) / float(best)\n",
    "       scores.append(score)\n",
    "\n",
    "   return np.mean(scores)\n",
    "\n",
    "\n",
    "# NDCG Scorer function\n",
    "ndcg_scorer = make_scorer(ndcg_score, needs_proba= True, k=5)\n",
    "\n",
    "import sklearn.grid_search as gs\n",
    "\n",
    "max_depth_values = [5, 6, 7]\n",
    "learning_rate_values = [0.1, 0.15]\n",
    "subsample_values = [0.7]\n",
    "colsample_bytree_values = [0.7]\n",
    "n_estimators = [100] #, 200\n",
    "# gamma = [0]\n",
    "\n",
    "params = {'max_depth' : max_depth_values, 'learning_rate': learning_rate_values, \n",
    "          'subsample': subsample_values, 'colsample_bytree': colsample_bytree_values,\n",
    "          'n_estimators' : n_estimators \n",
    "          #'gamma': gamma,\n",
    "          #'min_child_weight': min_child_weight\n",
    "         }\n",
    "\n",
    "clf = gs.GridSearchCV(model2, params, scoring=ndcg_scorer, cv=5)\n",
    "\n",
    "clf.fit(train_xvec, train_ytrans)\n",
    "\n",
    "clf.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred2 = clf.predict_proba(test_xvec)\n",
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id = test_m['id']\n",
    "\n",
    "ids = []  #list of ids\n",
    "cts = []  #list of countries\n",
    "for i in range(len(test_id)):\n",
    "    idx = test_id[i]\n",
    "    ids += [idx] * 5\n",
    "    cts += le.inverse_transform(np.argsort(pred2[i])[::-1])[:5].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub1 = pd.DataFrame(np.column_stack((ids, cts)), columns=['id', 'country'])\n",
    "print sub1.head\n",
    "sub1.to_csv('sub1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
